Things to do:

- Domain functions used in composites should inherit the domain from their parent
- Ability to create harmonic wavetables from arbitrary harmonic amplitudes and phases
	TableOsc can then be used to synthesize "nonharmonic" waveforms
- Add function to compute "opacity" of signal, e.g., the number of peaks in a spectrum
- Replace FFTW in favor of something with a more liberal license


-- 2/3/07

		period			freq
Delay	(v sr) / N		(sr / v) / N
		(v / sr) / N	1 / (v sr) / N
Osc		1 / (v sr)		v / sr


-- 2/15/07

Sync is short for synchronize and means to cause to operate at the same time or rate.  This is not to be confused with the term 'synchronous' which only has temporal implications.  It may be more clear to rename Sync to Sampler and Synced to Sampled, however these do not really imply a rate.

spu and ups could possibly be renamed, respectively, to rate and interval.  However, since Sync is mixed in a lot, rate and interval might be too common of names and cause conflicts.  A definite example is the Sampler which has its own rate method for changing the playback speed.


Interesting effects may be possible based on the reconstruction of a signal from its zero crossings.  Reference: BF Logan, Jr. "Information in the Zero Crossings of Bandpass Signals", Bell System Technical. Journal, vol. 56, pp. 487-510, April 1977 


-- 3/5/07

How should a Sync update Synceds?  An array, a linked list?

				Localized	Insertion	Deletion	Memory
Array			Yes			O(1) *		O(N)		N
Linked list		No			O(1)		O(1)		N * 2

	* assuming the array is large enough

The array wins for traversal.  It is better localized and smaller in memory.
The linked list wins for speed of insertions and deletions.

Traversal is less critical since changing the SPU, and thus updating the Synceds, will happen rarely. Fast insertion and deletion times are more critical since objects will be created and destroyed more often.  A linked list approach will require two additional pointer members in each Synced, but who's counting bytes anyway.


-- 3/8/07

Normally table oscillators are reader taps on a shared array.  It would be interesting to have a table osc that holds its own array and reads and writes a sample every iteration.  Could do plucked string like things with it.


-- 3/11/07

The random utilities are kind of a mess right now.  There are two different generators, linear congruential and Tausworthe, that have very similar methods.  Also the RndOp functions assume you want to use the Tausworthe RNG, but it would be nice to use LC as well.

All random number generation is based off one method that returns a uniform random unsigned integer.  This includes floating point, ranges, distributions, etc.  To simplify the code by removing duplication, the RNG classes could just have one main method, an overloaded (), that returns a uniform unsigned long.


-- 4/1/07

There a lots of interesting things to derive from a fixed point phase accumulator.  Ramps are most obvious, but also derivable are square and triangle waves.  The square wave is the fastest since only the top bit is used to set the sign of a set floating point number.  Ramp is almost as fast, but requires an offset because of the exponent ranges ([1,2), [2,4), etc.) of floating point numbers.  The triangle is most complicated requiring phase complementing logic.  A phase acc can also be used as a lightweight scheduler!  If a downward edge occurs, i.e. the MSB changing from 1 to 0, then execute your action and update the period of accumulator.

Another interesting thing about the acc, is that it naturally gives you all the higher octaves of the base frequency.  Because the higher octaves are subject to Nyquist foldover (of their fundamental pitch), the base frequency must be low enough to avoid this.  For example, if reading the first octave, the base frequency must be less than SR/4.

...
..1
.1.
.11
1..
1.1
11.
111


-- 7/26/07

At some point it may be wise automatically create array operations from scalar operations rather than doing it ad hocly as it is done now.  Unfortunately, this will require use of macros which will make the code harder to read and auto-doc.

So for something sensible, like max, we have several possibilities:

T max(T value1, T value2);
void max(T * arr, ULONG len, T value);
void max(T * arr, const T * src, ULONG len);	// err, maybe don't generate this one??

T clip(T value, T max, T min);
void clip(T * arr, ULONG len, T max, T min);

The policy is that all scalar ops have an array op that repeatedly applies the scalar op to several elements.

#define DEF_RANKS(name, params, exp)\
	T name(T value, params){ exp }
	void name(T * arr, ULONG len, params){
		LOOP_P(len, *arr = name(*arr, __WHAT__ )) 
	}



-- 7/28/07

Sliding windows are used often for performing signal analysis, most notably with the STFT.  Unfortunately, designing a flexible and efficient sliding window class is proving quite difficult.  There seem to be two techniques for buffering data: 1) use a small hop ring and shift samples left every hop, 2) use a ring the size of the window and unwrap (copy) samples to another buffer.  (1) has the advantage of requiring window size memory and (2) has the advantage of doing less copying if a windowing function needs to be applied.  The simplest solution is to provide support for both methods.



-- 9/20/07

Extending arithmetic functors to handle arbitrary numerical ADTs, such as an array object, is problematic.  First of all, all the standard arithmetic operators (+, -, =, *, /) must be defined by the ADT.  This is not so much a problem as the compiler will complain if the operation is not implemented.  However, some static functions, like sin() and cos(), are not defined for ADTs.  These would all have to be redefined elsewhere and in terms of the possible set of overloadable operators in C++.  Another issue involves the data involved in the main processing of the functor.  We want to avoid unnecessarily copying large data structures.  For inputs, it no problem since they can be passed by constant references.  However, careful consideration must be made when returning functor outputs and creating temporary local computation variables.  One possibility is to store static versions of these variables within the class.  In the end, the simplest solution may be to create arrays of simpler scalar functors, rather than a single functor that can process ADTs.

In general, I have encountered three usage cases of functors:
	#1 Serial processing of scalar sequences
	#2 Parallel processing of array sequences with shared parameters
	#3 Parallel processing of array sequences with unique parameters

#2 and #3 hint at the notion of separating the functor's parametric state from its process state.

Consider as a test case the construction of multi-tap and single-tap delay lines from some more atomic objects.

DelayParams{			// state of Delay parameters
	uint size;
	T * buffer;
	uint tapW;
}

DelayProcess{			// state of Delay process
	unit tapR;
}

Delay : DelayParams{	// single-tap
	DelayData proc;	
}

Delays : DelayParams{	// multi-tap
	DelayData * proc;
}


And another used for simple one-pole filters:

OnePoleParams{
	real freq;
	T co1, ci0;
}

OnePoleProcess{
	T o1;
}

OnePole : OnePoleParams{
	OnePoleProcess proc;
}

OnePoles : OnePoleParams{
	OnePoleProcess * proc;
}


Let's say we have the following tasks, 

	#1 filter a sequence serially
	#2 filter several sequences in parallel using identical parameters
	#3 filter several sequences in parallel using unique parameters

#1 is a special case of #3 (or vice-versa).  We either use 1 or N OnePole objects.  Case #2, however, is different since many filters are sharing the same set of parameters.  For #2, we can bind one parameter state to several process states to obtain better memory efficiency and a simpler control mechanism.  In contrast, #1 and #3 bind exclusively one parameter state to one process state.  In this case it doesn't matter if we use one object or an array of objects.


11/25/07

The Sync and Synced objects store both the samples/unit and units/samples variables.  If one or the other was computed lazily then we could save on one double per Synced object.  At the moment, it appears that ups() is the most often called, so it might make sense to make spu() the computed call.



12/20/07

When implementing a delay-line, do we read then write (RW) or write then read (WR)?
With RW the min delay is 1, the max is N. 
With WR the min delay is 0, the max is N-1.

For the standard delay-line, we want to WR, otherwise we can't get delays less than 1 sample.  In this case, the write tap must be pre-incremented before storing the new input value.  The algorithm is:
	
	w += inc;			// inc write tap
	buf[w] = i;			// write input sample
	o = buf[w - d];		// read delayed sample

Comb filters, however, have their own requirements since we must write a filtered output sample to the delay-line.  Thus the process must be RW.  The algorithm is:

	o = buf[w - d];		// read delayed sample
	o = cf*i + cb*o;	// filter
	buf[w] = o;			// write filtered sample
	w += inc;			// inc write tap

With post-inc, a delay of 0 incorrectly gets the oldest sample and delays greater than 1 get the proper sample.  With pre-inc, the delay times are always incorrectly one sample behind.



5/10/08

There are two policies generators can follow when returning a value from their generation operator. They can either return the next or the previously generated value. If they return the next value, the generation function is simpler, but setting parameters is less intuitive. Vice versa, if the previous value is returned, the generation function needs to cache the previous value, however, setting parameters is intuitive. The following illustrates how both methods would be used to generate an integer sequence from 0-9 using recursive addition. 

	struct RAdd{

		int genNext(){ return ++val; }
		int genPrev(){ int t=val; val++; return t; }

		int val;
	}

	RAdd rAdd;

	rAdd.val = -1;				// value set one behind start value
	for(int i=0; i<10; i++)
		rAdd.genNext();			// produces 0, 1, 2, ...

	rAdd.val = 0;				// value set to start value
	for(int i=0; i<10; i++)
		rAdd.genPrev();			// produces 0, 1, 2, ...
		




7/9/08

Composite ugens are somewhat inefficient and inflexible at the moment because they 1) cannot be easily synchronized to a domain and 2) each child ugen has redundant Synced data. One possible solution is that ugens use a curiously recurring template and strategy to specify their Synced. Single ugens will use the standard Synced object (with pointers and scale factors) while composited ugens will use a UnitSynced (without any data members).

Currently, all ugens are by default members of a domain. This simplifies their usage, however, makes them less efficient as members of a composite ugen since they each store their own domain units even though they share the same properties as the parent. It might be better if the lowest level ugens use a unit domain as their basis (i.e., freq from 0 to 0.5, phase from 0 to 1).


	class Sine{

		Sine(float f, float p): p0(p), p1(f){}

		void freq (float v){ p1 = v*M_2PI; }
		void phase(float v){ p0 = v*M_2PI; }

		float operator()(){
			p0 = wrap(p0);
			float r = sin(p0);
			p0 += p1;
			return r;
		}
		
		// change in sampling rate (ratio = new/old)
		virtual void onRateChange(double ratio){ p1 /= ratio; }

		float p0, p1;	// 0 and 1 derivative of phase
	};


To simplify units throughout the system, we will constrain ugen parameters to be between -1 and 1.



8/16/08

Lib			Any Size?	In-place
-----------------------------------------
FFTW		x			x
Ooura					x
KISS		x			



11/7/09

A generic approach to accessing/manipulating arrayed data:

	index map + data pointer

An indexer maps a natural number sequence (0, 1, 2, 3, etc.) onto on integer 
sequence.
There are 3 brands of index maps. 
They are listed in order of increasing generality and processing time/memory usage.

No-op					0 1 2 3
Integer Stride			0 2 4 6, 0 -2 -4 -6
Real Stride				0 2 4 6 1 3 5 7


All indexers have:
	- a count
	- an index mapping operator
	
The size of the source array is always assumed to be floor(stride) * count.


/// No-op index map
class Indexer{

	int32_t operator()(int32_t i) const { return i; }

protected:
	int32_t mCount;
}


/// Integer strided index generator
class IndexerInt : public Indexer {

	int32_t operator()(int32_t i) const { return i*stride(); }

protected:
	int32_t mStride;
};


/// Real strided index generator
class IndexerReal : public Indexer {

	int32_t operator()(int32_t i) const { return wrap(i*stride(), size()); }

protected:
	double mStride, mSize;
};


/// Table lookup index generator
class IndexerTable : public Indexer {

	int32_t operator()(int32_t i) const { return mTable[i]; }

protected:
	int32_t mTable;
}






